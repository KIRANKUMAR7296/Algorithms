{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What should we do with the Data First ?\n",
    "\n",
    "1. **Visualize** your Data\n",
    "\n",
    "2. **describe()** : Statistical Description of Data\n",
    "\n",
    "3. Use **Pandas Profiling** ( Interactive Report, Descriptive Statistics, Correlations, Distribution of Data )\n",
    "\n",
    "4. Check for **Duplicates** : ( drop_duplicates() )\n",
    "\n",
    "5. Beware of **Missing** Values : **isnull().sum()** ( **dropna()** or **fillna()** or **SimpleImputer** )\n",
    "\n",
    "\n",
    "Communicate with Subject Matter Experts ( **SMEs** ) : Product Manager or Customer for whom you are Creating Model.\n",
    "\n",
    "**Overfitting** : When your Model Captures **Patterns** in your Training Data too well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  target  \n",
       "0          0.4601                  0.11890       0  \n",
       "1          0.2750                  0.08902       0  \n",
       "2          0.3613                  0.08758       0  \n",
       "3          0.6638                  0.17300       0  \n",
       "4          0.2364                  0.07678       0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "df = load_breast_cancer()\n",
    "bc = pd.DataFrame(df.data, columns = df.feature_names)\n",
    "bc['target'] = pd.Series(df.target)\n",
    "bc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preventing Overfitting  \n",
    "\n",
    "Lasso Regularization ( L1 ) :  Reduce or Eliminate Weights in our Model by adding Penalty \n",
    "\n",
    "Ridge Regularization ( L2 ) : Reduce Weights in our Model by adding Penalty "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X, y = bc.iloc[:, :-1].values, bc.iloc[:, -1].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size = 0.3, \n",
    "                                                    random_state = 0, \n",
    "                                                    stratify = y) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale Features\n",
    "\n",
    "We Learn **Scaling** Parameters while Training and Apply on Test Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**L1** | LASSO Regularization in a Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy : 98.24%\n",
      "Test Accuracy : 94.15%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(penalty='l1', \n",
    "                           C=0.1, \n",
    "                           solver='liblinear', \n",
    "                           multi_class='ovr')\n",
    "model.fit(X_train, y_train)\n",
    "print(f'Training Accuracy : {model.score(X_train, y_train)*100:.2f}%')\n",
    "print(f'Test Accuracy : {model.score(X_test, y_test)*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**L2** | Ridge Regularization in a Logistic Regression Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy : 99.25%\n",
      "Test Accuracy : 96.49%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(penalty='l2', \n",
    "                           C=0.1, \n",
    "                           solver='liblinear', \n",
    "                           multi_class='ovr')\n",
    "model.fit(X_train, y_train)\n",
    "print(f'Training Accuracy : {model.score(X_train, y_train)*100:.2f}%')\n",
    "print(f'Test Accuracy : {model.score(X_test, y_test)*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Leakage**\n",
    "\n",
    "Information outside your Training Set enters your Model\n",
    "\n",
    "How to **Detect** and **Prevent** Data Leakage\n",
    "\n",
    "Any Feature surprisingly High Correlated with Target Variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_bill</th>\n",
       "      <th>tip</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>total_bill</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>67.573411</td>\n",
       "      <td>59.831513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tip</th>\n",
       "      <td>67.573411</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>48.929878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>size</th>\n",
       "      <td>59.831513</td>\n",
       "      <td>48.929878</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            total_bill         tip        size\n",
       "total_bill  100.000000   67.573411   59.831513\n",
       "tip          67.573411  100.000000   48.929878\n",
       "size         59.831513   48.929878  100.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "tips = sns.load_dataset('tips')\n",
    "tips.corr()*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imbalanced Data\n",
    "\n",
    "Number of Observations per class are Disproportionately Distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.166565</td>\n",
       "      <td>1.838346</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.068551</td>\n",
       "      <td>-0.084661</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.138849</td>\n",
       "      <td>-1.414872</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.456516</td>\n",
       "      <td>-1.368027</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.844214</td>\n",
       "      <td>0.228990</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature1  feature2  target\n",
       "0  1.166565  1.838346       2\n",
       "1  0.068551 -0.084661       2\n",
       "2  0.138849 -1.414872       2\n",
       "3  2.456516 -1.368027       2\n",
       "4  0.844214  0.228990       2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X,y = make_classification(n_samples=100, \n",
    "                          n_features=2, \n",
    "                          n_informative=2, \n",
    "                          n_redundant=0, \n",
    "                          n_repeated=0, \n",
    "                          n_classes=3, \n",
    "                          n_clusters_per_class=1, \n",
    "                          weights=[0.01, 0.05, 0.94], \n",
    "                          class_sep=0.8, \n",
    "                          random_state=0)\n",
    "\n",
    "df = pd.DataFrame(X)\n",
    "df.columns = ['feature1','feature2']\n",
    "df['target'] = y\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['target'].astype(str).hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying **Over Sampling** Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "sample = RandomOverSampler(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_resampled,y_resampled = sample.fit_resample(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAL1UlEQVR4nO3cf6jd9X3H8edrSUvX3DYqrpcQZXEg3UQZw8vWTSj3zglZW6b/yCyuJEXIP1tnx/ZHtn/65yzMQnH7J9QuGQu9uChEJmyTrFIGm9SokNq7NqVzqWmWtFNjK7IivPfHPaUxuck9nh/35J08HxDu+X7v93s/75AvT775cs9JVSFJ6ufnZj2AJGk0BlySmjLgktSUAZekpgy4JDW1eSMXu/7662vHjh0jnfvmm2+yZcuWyQ4kDXh9adrGucaOHj36w6r6hfP3b2jAd+zYwXPPPTfSuc888wyLi4uTHUga8PrStI1zjSX577X2+whFkpoy4JLUlAGXpKYMuCQ1ZcAlqSkDLklNGXBJasqAS1JTBlySmtrQd2KO49jJs+ze+9RM1n75oY/PZF1tHK+vq8OOGf0bA+zfOfmPavAOXJKaMuCS1JQBl6SmDLgkNWXAJakpAy5JTRlwSWrKgEtSUwZckpoy4JLUlAGXpKYMuCQ1ZcAlqSkDLklNGXBJasqAS1JTBlySmjLgktSUAZekpgy4JDVlwCWpKQMuSU0ZcElqyoBLUlMGXJKaMuCS1NRQAU/yJ0leSvKNJF9J8r4k1yV5Osnxwddrpz2sJOln1g14ku3AHwMLVXUrsAm4D9gLHKmqm4Ejg21J0gYZ9hHKZuDnk2wG3g98H7gbODD4/gHgnolPJ0m6qHUDXlUngb8CTgCngLNV9S/AfFWdGhxzCvjQNAeVJL1TqurSB6w+234c+H3gdeAfgEPAX1fVNecc91pVXfAcPMkeYA/A/Pz87cvLyyMNeubVs5x+a6RTx3bb9q2zWVgbxuvr6nDs5NmZrX3T1k3Mzc2NdO7S0tLRqlo4f//mIc79HeC/quoHAEmeAH4LOJ1kW1WdSrINOLPWyVW1D9gHsLCwUIuLiyP9BR45eJiHjw0z7uS9fP/iTNbVxvH6ujrs3vvUzNbev3MLo/bvYoZ5Bn4C+EiS9ycJcCewAjwJ7Bocsws4PNHJJEmXtO4tR1U9m+QQ8DzwNvACq3fUc8BjSR5gNfL3TnNQSdI7DfV/xqr6HPC583b/H6t345KkGfCdmJLUlAGXpKYMuCQ1ZcAlqSkDLklNGXBJasqAS1JTBlySmjLgktSUAZekpgy4JDVlwCWpKQMuSU0ZcElqyoBLUlMGXJKaMuCS1JQBl6SmDLgkNWXAJakpAy5JTRlwSWrKgEtSUwZckpoy4JLUlAGXpKYMuCQ1ZcAlqSkDLklNGXBJasqAS1JTBlySmjLgktSUAZekpgy4JDU1VMCTXJPkUJL/TLKS5DeTXJfk6STHB1+vnfawkqSfGfYO/IvAP1XVLwO/CqwAe4EjVXUzcGSwLUnaIOsGPMkHgY8CjwJU1U+q6nXgbuDA4LADwD3TGVGStJZh7sB/CfgB8LdJXkjypSRbgPmqOgUw+PqhKc4pSTpPqurSByQLwH8Ad1TVs0m+CLwBfKaqrjnnuNeq6oLn4En2AHsA5ufnb19eXh5p0DOvnuX0WyOdOrbbtm+dzcLaMF5fV4djJ8/ObO2btm5ibm5upHOXlpaOVtXC+fs3D3HuK8ArVfXsYPsQq8+7TyfZVlWnkmwDzqx1clXtA/YBLCws1OLi4ijz88jBwzx8bJhxJ+/l+xdnsq42jtfX1WH33qdmtvb+nVsYtX8Xs+4jlKr6H+B7ST482HUn8E3gSWDXYN8u4PBEJ5MkXdKwtxyfAQ4meS/wXeDTrMb/sSQPACeAe6czoiRpLUMFvKpeBC54/sLq3bgkaQZ8J6YkNWXAJakpAy5JTRlwSWrKgEtSUwZckpoy4JLUlAGXpKYMuCQ1ZcAlqSkDLklNGXBJasqAS1JTBlySmjLgktSUAZekpgy4JDVlwCWpKQMuSU0ZcElqyoBLUlMGXJKaMuCS1JQBl6SmDLgkNWXAJakpAy5JTRlwSWrKgEtSUwZckpoy4JLUlAGXpKYMuCQ1ZcAlqSkDLklNGXBJamrogCfZlOSFJP842L4uydNJjg++Xju9MSVJ53s3d+APAivnbO8FjlTVzcCRwbYkaYMMFfAkNwAfB750zu67gQOD1weAeyY6mSTpklJV6x+UHAL+EvgA8GdV9Ykkr1fVNecc81pVXfAYJckeYA/A/Pz87cvLyyMNeubVs5x+a6RTx3bb9q2zWVgbxuvr6nDs5NmZrX3T1k3Mzc2NdO7S0tLRqlo4f//m9U5M8gngTFUdTbL4bheuqn3APoCFhYVaXHzXPwKARw4e5uFj6447FS/fvziTdbVxvL6uDrv3PjWztffv3MKo/buYYa7YO4DfS/Ix4H3AB5P8PXA6ybaqOpVkG3BmopNJki5p3WfgVfXnVXVDVe0A7gP+tar+AHgS2DU4bBdweGpTSpIuMM7vgT8E3JXkOHDXYFuStEHe1UO/qnoGeGbw+n+BOyc/kiRpGL4TU5KaMuCS1JQBl6SmDLgkNWXAJakpAy5JTRlwSWrKgEtSUwZckpoy4JLUlAGXpKYMuCQ1ZcAlqSkDLklNGXBJasqAS1JTBlySmjLgktSUAZekpgy4JDVlwCWpKQMuSU0ZcElqyoBLUlMGXJKaMuCS1JQBl6SmDLgkNWXAJakpAy5JTRlwSWrKgEtSUwZckpoy4JLUlAGXpKbWDXiSG5N8NclKkpeSPDjYf12Sp5McH3y9dvrjSpJ+apg78LeBP62qXwE+AvxhkluAvcCRqroZODLYliRtkHUDXlWnqur5wesfASvAduBu4MDgsAPAPVOaUZK0hlTV8AcnO4CvAbcCJ6rqmnO+91pVXfAYJckeYA/A/Pz87cvLyyMNeubVs5x+a6RTx3bb9q2zWVgbxuvr6nDs5NmZrX3T1k3Mzc2NdO7S0tLRqlo4f//mYX9AkjngceCzVfVGkqHOq6p9wD6AhYWFWlxcHHbJd3jk4GEePjb0uBP18v2LM1lXG8fr6+qwe+9TM1t7/84tjNq/ixnqt1CSvIfVeB+sqicGu08n2Tb4/jbgzEQnkyRd0jC/hRLgUWClqr5wzreeBHYNXu8CDk9+PEnSxQzzf8Y7gE8Bx5K8ONj3F8BDwGNJHgBOAPdOZUJJ0prWDXhV/RtwsQfed052HEnSsHwnpiQ1ZcAlqSkDLklNGXBJasqAS1JTBlySmjLgktSUAZekpgy4JDVlwCWpKQMuSU0ZcElqyoBLUlMGXJKaMuCS1JQBl6SmDLgkNWXAJakpAy5JTRlwSWrKgEtSUwZckpoy4JLUlAGXpKYMuCQ1ZcAlqSkDLklNGXBJasqAS1JTBlySmjLgktSUAZekpgy4JDVlwCWpKQMuSU2NFfAkO5N8K8l3kuyd1FCSpPWNHPAkm4C/AX4XuAX4ZJJbJjWYJOnSxrkD/3XgO1X13ar6CbAM3D2ZsSRJ69k8xrnbge+ds/0K8BvnH5RkD7BnsPnjJN8acb3rgR+OeO5Y8vlZrKoN5vWlqVr6/FjX2C+utXOcgGeNfXXBjqp9wL4x1lldLHmuqhbG/TnSWry+NG3TuMbGeYTyCnDjOds3AN8fbxxJ0rDGCfjXgZuT3JTkvcB9wJOTGUuStJ6RH6FU1dtJ/gj4Z2AT8OWqemlik11o7Mcw0iV4fWnaJn6NpeqCx9aSpAZ8J6YkNWXAJampyz7gSW5M8tUkK0leSvLgrGfSlSPJl5OcSfKNWc+iK9M0P3Lksn8GnmQbsK2qnk/yAeAocE9VfXPGo+kKkOSjwI+Bv6uqW2c9j64sg48c+TZwF6u/ev114JOT6tdlfwdeVaeq6vnB6x8BK6y+C1QaW1V9DXh11nPoijXVjxy57AN+riQ7gF8Dnp3xKJI0jLU+cmRiN6BtAp5kDngc+GxVvTHreSRpCEN95MioWgQ8yXtYjffBqnpi1vNI0pCm+pEjl33AkwR4FFipqi/Meh5Jehem+pEjl33AgTuATwG/neTFwZ+PzXooXRmSfAX4d+DDSV5J8sCsZ9KVo6reBn76kSMrwGOT/MiRy/7XCCVJa+twBy5JWoMBl6SmDLgkNWXAJakpAy5JTRlwSWrKgEtSU/8P0aCoBf0WAAQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame(y_resampled)\n",
    "df[0].astype(str).hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying **Under Sampling** Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "sample = RandomUnderSampler(random_state=0)\n",
    "X_resampled, y_resampled = sample.fit_resample(X,y)\n",
    "df = pd.DataFrame(y_resampled)\n",
    "df[0].astype(str).hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting Coefficients with Multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "iris = sns.load_dataset('iris')\n",
    "iris.head()\n",
    "iris = iris[iris['species'] != 'setosa']\n",
    "iris['species'] = iris['species'].apply(lambda x : 1 if x == 'versicolor' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']]\n",
    "y = iris['species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.059493\n",
      "         Iterations 12\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                species   No. Observations:                  100\n",
      "Model:                          Logit   Df Residuals:                       95\n",
      "Method:                           MLE   Df Model:                            4\n",
      "Date:                Thu, 08 Apr 2021   Pseudo R-squ.:                  0.9142\n",
      "Time:                        20:49:04   Log-Likelihood:                -5.9493\n",
      "converged:                       True   LL-Null:                       -69.315\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.947e-26\n",
      "================================================================================\n",
      "                   coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "const           42.6378     25.708      1.659      0.097      -7.748      93.024\n",
      "sepal_length     2.4652      2.394      1.030      0.303      -2.228       7.158\n",
      "sepal_width      6.6809      4.480      1.491      0.136      -2.099      15.461\n",
      "petal_length    -9.4294      4.737     -1.990      0.047     -18.714      -0.145\n",
      "petal_width    -18.2861      9.743     -1.877      0.061     -37.381       0.809\n",
      "================================================================================\n",
      "\n",
      "Possibly complete quasi-separation: A fraction 0.60 of observations can be\n",
      "perfectly predicted. This might indicate that there is complete\n",
      "quasi-separation. In this case some parameters will not be identified.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.tools.tools import add_constant\n",
    "\n",
    "X = add_constant(X)\n",
    "model = sm.Logit(y, X)\n",
    "result = model.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**VIF** : Variance Inflation Factor\n",
    "    \n",
    "Extent to which we have Multicollinearity in our result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "vif = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>const</td>\n",
       "      <td>125.170277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sepal_length</td>\n",
       "      <td>3.990113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sepal_width</td>\n",
       "      <td>1.721954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>petal_length</td>\n",
       "      <td>7.252447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petal_width</td>\n",
       "      <td>3.948354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0           1\n",
       "0         const  125.170277\n",
       "1  sepal_length    3.990113\n",
       "2   sepal_width    1.721954\n",
       "3  petal_length    7.252447\n",
       "4   petal_width    3.948354"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(list(zip(list(X.columns), vif)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To Treat Multicollinearity we can **remove** Variable with **High VIF**\n",
    "\n",
    "### Evaluating by Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(n_samples=1000, \n",
    "                           n_features=2, \n",
    "                           n_informative=2, \n",
    "                           n_redundant=0, \n",
    "                           n_repeated=0, \n",
    "                           n_classes=2, \n",
    "                           n_clusters_per_class=1, \n",
    "                           weights=[0.95, 0.05], \n",
    "                           class_sep=0.8, \n",
    "                           random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function make_classification in module sklearn.datasets._samples_generator:\n",
      "\n",
      "make_classification(n_samples=100, n_features=20, *, n_informative=2, n_redundant=2, n_repeated=0, n_classes=2, n_clusters_per_class=2, weights=None, flip_y=0.01, class_sep=1.0, hypercube=True, shift=0.0, scale=1.0, shuffle=True, random_state=None)\n",
      "    Generate a random n-class classification problem.\n",
      "    \n",
      "    This initially creates clusters of points normally distributed (std=1)\n",
      "    about vertices of an ``n_informative``-dimensional hypercube with sides of\n",
      "    length ``2*class_sep`` and assigns an equal number of clusters to each\n",
      "    class. It introduces interdependence between these features and adds\n",
      "    various types of further noise to the data.\n",
      "    \n",
      "    Without shuffling, ``X`` horizontally stacks features in the following\n",
      "    order: the primary ``n_informative`` features, followed by ``n_redundant``\n",
      "    linear combinations of the informative features, followed by ``n_repeated``\n",
      "    duplicates, drawn randomly with replacement from the informative and\n",
      "    redundant features. The remaining features are filled with random noise.\n",
      "    Thus, without shuffling, all useful features are contained in the columns\n",
      "    ``X[:, :n_informative + n_redundant + n_repeated]``.\n",
      "    \n",
      "    Read more in the :ref:`User Guide <sample_generators>`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    n_samples : int, default=100\n",
      "        The number of samples.\n",
      "    \n",
      "    n_features : int, default=20\n",
      "        The total number of features. These comprise ``n_informative``\n",
      "        informative features, ``n_redundant`` redundant features,\n",
      "        ``n_repeated`` duplicated features and\n",
      "        ``n_features-n_informative-n_redundant-n_repeated`` useless features\n",
      "        drawn at random.\n",
      "    \n",
      "    n_informative : int, default=2\n",
      "        The number of informative features. Each class is composed of a number\n",
      "        of gaussian clusters each located around the vertices of a hypercube\n",
      "        in a subspace of dimension ``n_informative``. For each cluster,\n",
      "        informative features are drawn independently from  N(0, 1) and then\n",
      "        randomly linearly combined within each cluster in order to add\n",
      "        covariance. The clusters are then placed on the vertices of the\n",
      "        hypercube.\n",
      "    \n",
      "    n_redundant : int, default=2\n",
      "        The number of redundant features. These features are generated as\n",
      "        random linear combinations of the informative features.\n",
      "    \n",
      "    n_repeated : int, default=0\n",
      "        The number of duplicated features, drawn randomly from the informative\n",
      "        and the redundant features.\n",
      "    \n",
      "    n_classes : int, default=2\n",
      "        The number of classes (or labels) of the classification problem.\n",
      "    \n",
      "    n_clusters_per_class : int, default=2\n",
      "        The number of clusters per class.\n",
      "    \n",
      "    weights : array-like of shape (n_classes,) or (n_classes - 1,),              default=None\n",
      "        The proportions of samples assigned to each class. If None, then\n",
      "        classes are balanced. Note that if ``len(weights) == n_classes - 1``,\n",
      "        then the last class weight is automatically inferred.\n",
      "        More than ``n_samples`` samples may be returned if the sum of\n",
      "        ``weights`` exceeds 1. Note that the actual class proportions will\n",
      "        not exactly match ``weights`` when ``flip_y`` isn't 0.\n",
      "    \n",
      "    flip_y : float, default=0.01\n",
      "        The fraction of samples whose class is assigned randomly. Larger\n",
      "        values introduce noise in the labels and make the classification\n",
      "        task harder. Note that the default setting flip_y > 0 might lead\n",
      "        to less than ``n_classes`` in y in some cases.\n",
      "    \n",
      "    class_sep : float, default=1.0\n",
      "        The factor multiplying the hypercube size.  Larger values spread\n",
      "        out the clusters/classes and make the classification task easier.\n",
      "    \n",
      "    hypercube : bool, default=True\n",
      "        If True, the clusters are put on the vertices of a hypercube. If\n",
      "        False, the clusters are put on the vertices of a random polytope.\n",
      "    \n",
      "    shift : float, ndarray of shape (n_features,) or None, default=0.0\n",
      "        Shift features by the specified value. If None, then features\n",
      "        are shifted by a random value drawn in [-class_sep, class_sep].\n",
      "    \n",
      "    scale : float, ndarray of shape (n_features,) or None, default=1.0\n",
      "        Multiply features by the specified value. If None, then features\n",
      "        are scaled by a random value drawn in [1, 100]. Note that scaling\n",
      "        happens after shifting.\n",
      "    \n",
      "    shuffle : bool, default=True\n",
      "        Shuffle the samples and the features.\n",
      "    \n",
      "    random_state : int, RandomState instance or None, default=None\n",
      "        Determines random number generation for dataset creation. Pass an int\n",
      "        for reproducible output across multiple function calls.\n",
      "        See :term:`Glossary <random_state>`.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    X : ndarray of shape (n_samples, n_features)\n",
      "        The generated samples.\n",
      "    \n",
      "    y : ndarray of shape (n_samples,)\n",
      "        The integer labels for class membership of each sample.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    The algorithm is adapted from Guyon [1] and was designed to generate\n",
      "    the \"Madelon\" dataset.\n",
      "    \n",
      "    References\n",
      "    ----------\n",
      "    .. [1] I. Guyon, \"Design of experiments for the NIPS 2003 variable\n",
      "           selection benchmark\", 2003.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    make_blobs : Simplified variant.\n",
      "    make_multilabel_classification : Unrelated generator for multilabel tasks.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(make_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(X)\n",
    "df.columns = ['feature1', 'feature2']\n",
    "df['target'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['prediction'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Model : 94.40%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(f'Accuracy of Model : {accuracy_score(df[\"target\"], df[\"prediction\"])*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### True Positive Rate ( Sensitivity )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00%\n"
     ]
    }
   ],
   "source": [
    "positive = df[df['target'] == 1]\n",
    "print(f'{accuracy_score(positive[\"target\"], positive[\"prediction\"])*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### True Negative Rate ( Specificity )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.00%\n"
     ]
    }
   ],
   "source": [
    "negative = df[df['target'] == 0]\n",
    "print(f'{accuracy_score(negative[\"target\"], negative[\"prediction\"])*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.200228</td>\n",
       "      <td>-1.126880</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.873630</td>\n",
       "      <td>0.999259</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.722953</td>\n",
       "      <td>0.106167</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.548422</td>\n",
       "      <td>1.903053</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.254758</td>\n",
       "      <td>2.445131</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature1  feature2  target  prediction\n",
       "0 -0.200228 -1.126880       0           0\n",
       "1 -0.873630  0.999259       0           0\n",
       "2 -0.722953  0.106167       0           0\n",
       "3 -0.548422  1.903053       0           1\n",
       "4 -1.254758  2.445131       0           1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "df['prediction'] = np.random.randint(0,2, df.shape[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      "[[508 436]\n",
      " [ 26  30]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(df['target'], df['prediction'])\n",
    "print(f'Confusion Matrix : \\n{cm}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(cm, annot=True, fmt='g');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recall** : Ability to Classifier to find all Positive Sample\n",
    "\n",
    "**Precision** : How Relevant our Result is \n",
    "\n",
    "**F1** Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall : 53.57%\n",
      "Precision : 6.44%\n",
      "F1 Score : 11.49%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "\n",
    "print(f'Recall : {recall_score(df[\"target\"], df[\"prediction\"])*100:.2f}%')\n",
    "\n",
    "print(f'Precision : {precision_score(df[\"target\"], df[\"prediction\"])*100:.2f}%')\n",
    "\n",
    "print(f'F1 Score : {f1_score(df[\"target\"], df[\"prediction\"])*100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
